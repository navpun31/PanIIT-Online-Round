{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Training\n",
    "\n",
    "This notebook contains the model used for training. \n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/you/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import morphology\n",
    "import pandas as pd\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam,RMSprop,SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('solution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model used contains 4 blocks. Each block contains 3 convolutional-batch normalization pairs followed by a dropout layer. The final output block of the network has a dense layer, followed by a batch normalization layer, followed by a dropout layer. Finally, the last dense layer with softmax activation is used for output.  \n",
    "\n",
    "\n",
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(128,128,1)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#-------------------\n",
    "\n",
    "model.add(Conv2D(128,(3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#--------------------\n",
    "\n",
    "model.add(Conv2D(256,(3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#--------------------------------\n",
    "\n",
    "# model.add(Conv2D(512,(3, 3)))\n",
    "# model.add(BatchNormalization(axis=-1))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(512, (3, 3)))\n",
    "# model.add(BatchNormalization(axis=-1))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(128,128,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,kernel_size=3,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=3,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,kernel_size=3,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256,kernel_size=3,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,kernel_size=3,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(512,kernel_size=3,activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(512,kernel_size=3,activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(512,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the preprocessed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in range(1,14891):\n",
    "    data.append(cv2.imread('v9/'+str(i)+'.png',0))\n",
    "\n",
    "data = np.array(data)\n",
    "data = data.astype(np.float16)\n",
    "data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.reshape(data,(14890,128,128,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the labels for all the original as well as augmented images used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = pd.read_csv('v9.csv')\n",
    "y = [i-1 for i in lab['category']]\n",
    "\n",
    "#y = [i-1 for i in train['category']]\n",
    "\n",
    "number_of_classes = 6\n",
    "\n",
    "Y = np_utils.to_categorical(y, number_of_classes)\n",
    "\n",
    "#Y = np.concatenate((Y,Y),axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2978, 128, 128, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,y_train,X_val,y_val = np.concatenate((data[:4000],data[6000:14000]),axis=0),np.concatenate((Y[:4000],Y[6000:14000]),axis=0),np.concatenate((data[4000:6000],data[14000:]),axis=0),np.concatenate((Y[4000:6000],Y[14000:]),axis=0)\n",
    "#X_train,y_train,X_val,y_val = np.concatenate((data[:4500],data[5500:]),axis=0),np.concatenate((Y[:4500],Y[5500:]),axis=0),data[4500:5500],Y[4500:5500]\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(data,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the optimizer for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "#Adding Callbacks and learning rate reductions\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=1, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = 0.1\n",
    "#epochs = 30\n",
    "#decay_rate = learning_rate / epochs\n",
    "#momentum = 0.8\n",
    "#sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making batches for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen = ImageDataGenerator(rotation_range=5, width_shift_range=0.08,\n",
    "                         #height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "\n",
    "test_gen = ImageDataGenerator()\n",
    "\n",
    "train_generator = gen.flow(X_train, y_train, batch_size=32)\n",
    "val_generator = test_gen.flow(X_val, y_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "\n",
    "The results obtained below are trained on model that had already been trained on model 2 for 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "372/372 [==============================] - 54s - loss: 7.4220e-04 - acc: 0.9999 - val_loss: 0.0408 - val_acc: 0.9940\n",
      "Epoch 2/30\n",
      "372/372 [==============================] - 53s - loss: 6.7248e-04 - acc: 0.9997 - val_loss: 0.0379 - val_acc: 0.9942\n",
      "Epoch 3/30\n",
      "372/372 [==============================] - 53s - loss: 6.1135e-04 - acc: 0.9997 - val_loss: 0.0431 - val_acc: 0.9932\n",
      "Epoch 4/30\n",
      "372/372 [==============================] - 53s - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0348 - val_acc: 0.9942\n",
      "Epoch 5/30\n",
      "372/372 [==============================] - 53s - loss: 1.5930e-04 - acc: 1.0000 - val_loss: 0.0454 - val_acc: 0.9932\n",
      "Epoch 6/30\n",
      "372/372 [==============================] - 53s - loss: 8.7062e-04 - acc: 0.9999 - val_loss: 0.0321 - val_acc: 0.9949\n",
      "Epoch 7/30\n",
      "372/372 [==============================] - 54s - loss: 9.0555e-04 - acc: 0.9998 - val_loss: 0.0475 - val_acc: 0.9929\n",
      "Epoch 8/30\n",
      "372/372 [==============================] - 53s - loss: 2.1295e-04 - acc: 0.9999 - val_loss: 0.0348 - val_acc: 0.9949\n",
      "Epoch 9/30\n",
      "372/372 [==============================] - 54s - loss: 4.3966e-04 - acc: 0.9999 - val_loss: 0.0434 - val_acc: 0.9936\n",
      "Epoch 10/30\n",
      "372/372 [==============================] - 52s - loss: 2.7729e-04 - acc: 0.9999 - val_loss: 0.0438 - val_acc: 0.9936\n",
      "Epoch 11/30\n",
      "372/372 [==============================] - 52s - loss: 3.7634e-04 - acc: 0.9999 - val_loss: 0.0409 - val_acc: 0.9939\n",
      "Epoch 12/30\n",
      "372/372 [==============================] - 53s - loss: 8.6762e-05 - acc: 1.0000 - val_loss: 0.0389 - val_acc: 0.9942\n",
      "Epoch 13/30\n",
      "372/372 [==============================] - 54s - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0507 - val_acc: 0.9932\n",
      "Epoch 14/30\n",
      "372/372 [==============================] - 53s - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0477 - val_acc: 0.9929\n",
      "Epoch 15/30\n",
      "372/372 [==============================] - 53s - loss: 3.2631e-04 - acc: 0.9999 - val_loss: 0.0237 - val_acc: 0.9966\n",
      "Epoch 16/30\n",
      "372/372 [==============================] - 53s - loss: 6.0452e-04 - acc: 0.9997 - val_loss: 0.0314 - val_acc: 0.9952\n",
      "Epoch 17/30\n",
      "372/372 [==============================] - 53s - loss: 1.2559e-04 - acc: 0.9999 - val_loss: 0.0551 - val_acc: 0.9925\n",
      "Epoch 18/30\n",
      "372/372 [==============================] - 53s - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0397 - val_acc: 0.9936\n",
      "Epoch 19/30\n",
      "372/372 [==============================] - 53s - loss: 1.6020e-04 - acc: 0.9999 - val_loss: 0.0573 - val_acc: 0.9922\n",
      "Epoch 20/30\n",
      "372/372 [==============================] - 53s - loss: 5.7803e-04 - acc: 0.9999 - val_loss: 0.0297 - val_acc: 0.9956\n",
      "Epoch 21/30\n",
      "372/372 [==============================] - 53s - loss: 6.8911e-04 - acc: 0.9999 - val_loss: 0.0478 - val_acc: 0.9929\n",
      "Epoch 22/30\n",
      "372/372 [==============================] - 53s - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0411 - val_acc: 0.9939\n",
      "Epoch 23/30\n",
      "372/372 [==============================] - 55s - loss: 7.0502e-04 - acc: 0.9997 - val_loss: 0.0436 - val_acc: 0.9936\n",
      "Epoch 24/30\n",
      "372/372 [==============================] - 55s - loss: 6.9550e-04 - acc: 0.9997 - val_loss: 0.0407 - val_acc: 0.9929\n",
      "Epoch 25/30\n",
      "372/372 [==============================] - 53s - loss: 1.8049e-04 - acc: 0.9999 - val_loss: 0.0578 - val_acc: 0.9922\n",
      "Epoch 26/30\n",
      "372/372 [==============================] - 53s - loss: 8.2931e-04 - acc: 0.9997 - val_loss: 0.0332 - val_acc: 0.9956\n",
      "Epoch 27/30\n",
      "372/372 [==============================] - 55s - loss: 2.3796e-04 - acc: 0.9999 - val_loss: 0.0430 - val_acc: 0.9936\n",
      "Epoch 28/30\n",
      "372/372 [==============================] - 54s - loss: 0.0020 - acc: 0.9997 - val_loss: 0.0382 - val_acc: 0.9936\n",
      "Epoch 29/30\n",
      "372/372 [==============================] - 54s - loss: 5.6365e-04 - acc: 0.9999 - val_loss: 0.0299 - val_acc: 0.9942\n",
      "Epoch 30/30\n",
      "372/372 [==============================] - 54s - loss: 1.8481e-04 - acc: 0.9999 - val_loss: 0.0492 - val_acc: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe73d5acfd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=11912//32, epochs=30, validation_data=val_generator, validation_steps=2978//32, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('aall_m100_99_56_3v9_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model = load_model('aall_m100_99_49_3v9_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "## Loading preprocessed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "\n",
    "for i in range(1,40001):\n",
    "    test.append(cv2.imread('test_v9/'+str(i)+'.png',0))\n",
    "    \n",
    "test = np.array(test)\n",
    "test = test.astype(np.float16)\n",
    "test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "\n",
    "We take 7 best models and perform a majority voting ensemble for our final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('aall_m100_99_56_3v9_2.h5')\n",
    "model2 = load_model('aall_m100_99_52_3v9_1.h5')\n",
    "model3 = load_model('aall_m100_99_49_3v9_1.h5')\n",
    "model4 = load_model('aall_m100_99_42_3v9_1.h5')\n",
    "model5 = load_model('aall_m100_99_29_3v9_1.h5')\n",
    "model6 = load_model('aall_m100_99_39_3v9_2.h5')\n",
    "model7 = load_model('aall_m100_99_25_3v9_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 54s    \n",
      "40000/40000 [==============================] - 59s    \n",
      "40000/40000 [==============================] - 59s    \n",
      "40000/40000 [==============================] - 59s    \n",
      "40000/40000 [==============================] - 56s    \n"
     ]
    }
   ],
   "source": [
    "test = np.reshape(test,(40000,128,128,1))\n",
    "\n",
    "a = []\n",
    "\n",
    "prediction1 = model1.predict_classes(test)\n",
    "prediction1 += 1\n",
    "a.append(prediction1)\n",
    "\n",
    "prediction2 = model2.predict_classes(test)\n",
    "prediction2 += 1\n",
    "a.append(prediction2)\n",
    "\n",
    "prediction3 = model3.predict_classes(test)\n",
    "prediction3 += 1\n",
    "a.append(prediction3)\n",
    "\n",
    "prediction4 = model4.predict_classes(test)\n",
    "prediction4 += 1\n",
    "a.append(prediction4)\n",
    "\n",
    "prediction5 = model5.predict_classes(test)\n",
    "prediction5 += 1\n",
    "a.append(prediction5)\n",
    "\n",
    "prediction6 = model6.predict_classes(test)\n",
    "prediction6 += 1\n",
    "a.append(prediction6)\n",
    "\n",
    "prediction7 = model7.predict_classes(test)\n",
    "prediction7 += 1\n",
    "a.append(prediction7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Voting Ensemble for 7 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(a)\n",
    "a = a.T\n",
    "\n",
    "final = []\n",
    "for i in a:\n",
    "    d = {}\n",
    "    for j in i:\n",
    "        if j in d:\n",
    "            d[j]+=1\n",
    "            continue\n",
    "        d[j] = 1\n",
    "    #if len(d)>1:\n",
    "        #print(i)\n",
    "    final.append(max(d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = list(range(1,40001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\n",
    "    'id' : ID,\n",
    "    'category' : final\n",
    "})\n",
    "sub[['id','category']].to_csv('sub_ensemble.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
